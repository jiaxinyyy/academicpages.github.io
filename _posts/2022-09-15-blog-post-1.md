---
title: 'Object Detection'
date: 2022-09-15
permalink: /posts/2022/09/blog-post-1/
tags:
  - cv
---

This is a blog post about the data preprocessing step of my AI studio project.


My group collaborates with engineers from American Express to develop a model to extract texts from customers’ documents, such as passports and driver licenses, to help the company process customers’ information, and the company can use the information and prevent business transactions with those on the US sanction list.

We approach the project in two ways.\
The first way is a pipeline method. We use the sample dataset of SmartDoc Challenge 1 as our dataset, which are video clips with documents and xml files containing the bounding box coordinates of the documents. We turn the videos into frames, which are jpg files. Then, we build a binary classification model (built upon CNN) using fastai to classify frames with documents and frames without documents. We take those frames with documents and crop the documents using the bounding box coordinates. To use OCR models to extract the texts, we improve the quality of the documents using OpenCV and PIL. The current result of this approach is we can get some of the texts. More image preprocessing needs to be done.

The second one is using the Pix2Seq model developed by Google Research. The model can take in images and output the bounding box coordinates and names of objects in the images. In our case, we expect the model to output the texts themselves. However, we do not have the text as labels in our dataset, the sample dataset of SmartDoc Challenge 1. Thus, we create a custom dataset of documents with random texts of random sizes/fonts/colors on random coordinates using PIL to finetune the model to recognize texts in various situations, and we have bounding box coordinates and texts as the labels. The current challenge of this approach is there are few resources we can refer to when working with this new model, and we haven’t figured out how to pass our dataset as the format the model can take.